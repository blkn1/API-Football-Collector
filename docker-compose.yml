version: "3.8"

services:
  postgres:
    image: postgres:15-alpine
    env_file:
      - ./.env
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-api_football}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Auto-load schemas on first init
      - ./db/schemas:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-api_football}"]
      interval: 5s
      timeout: 3s
      retries: 10
    # NOTE (Coolify/Traefik):
    # Do not force a custom network here. Let the platform attach its proxy
    # to the app network so domains can reach containers.

  redis:
    image: redis:7-alpine
    env_file:
      - ./.env
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10
    # see note above (Coolify/Traefik networking)

  # Scheduler: runs enabled non-live jobs from config/jobs/*.yaml
  collector:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - ./.env
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:postgres@postgres:5432/api_football}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-api_football}
      API_FOOTBALL_KEY: ${API_FOOTBALL_KEY}
      LOG_FILE: /app/logs/collector.jsonl
      # Cron evaluation timezone (DB timestamps remain UTC)
      SCHEDULER_TIMEZONE: ${SCHEDULER_TIMEZONE:-Europe/Istanbul}
      # Aşama 1: fill empty static tables on startup (idempotent)
      BOOTSTRAP_STATIC_ON_START: ${BOOTSTRAP_STATIC_ON_START:-1}

      # Aşama 4: rollout throttles (override in Coolify env)
      BACKFILL_FIXTURES_MAX_TASKS_PER_RUN: ${BACKFILL_FIXTURES_MAX_TASKS_PER_RUN:-20}
      # 60k/day target: reduce windows per task to keep total request volume ~55-60k/day (incl. overhead)
      BACKFILL_FIXTURES_MAX_PAGES_PER_TASK: ${BACKFILL_FIXTURES_MAX_PAGES_PER_TASK:-8}
      BACKFILL_FIXTURES_WINDOW_DAYS: ${BACKFILL_FIXTURES_WINDOW_DAYS:-30}
      BACKFILL_STANDINGS_MAX_TASKS_PER_RUN: ${BACKFILL_STANDINGS_MAX_TASKS_PER_RUN:-2}
      FIXTURE_DETAILS_BACKFILL_BATCH: ${FIXTURE_DETAILS_BACKFILL_BATCH:-25}
      # Season-wide fixture details backfill (events/players/statistics/lineups) - quota-safe growth knob
      FIXTURE_DETAILS_SEASON_BACKFILL_BATCH: ${FIXTURE_DETAILS_SEASON_BACKFILL_BATCH:-30}
      # Operational finalize + lineup window knobs
      FIXTURE_DETAILS_FINALIZE_BATCH: ${FIXTURE_DETAILS_FINALIZE_BATCH:-200}
      FIXTURE_LINEUPS_WINDOW_BATCH: ${FIXTURE_LINEUPS_WINDOW_BATCH:-200}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "scripts/healthcheck_collector.py"]
      interval: 10s
      timeout: 5s
      retries: 12
    command: ["sh", "-lc", "python scripts/apply_schemas.py && python -m src.collector.scheduler"]
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    # see note above (Coolify/Traefik networking)

  # Optional: live polling loop (/fixtures?live=all every 15s).
  # Set ENABLE_LIVE_LOOP=1 to actually run it; otherwise the container stays idle (does NOT call API).
  live_loop:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - ./.env
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:postgres@postgres:5432/api_football}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-api_football}
      API_FOOTBALL_KEY: ${API_FOOTBALL_KEY}
      LOG_FILE: /app/logs/collector.jsonl
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      ENABLE_LIVE_LOOP: ${ENABLE_LIVE_LOOP:-0}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "scripts/healthcheck_live_loop.py"]
      interval: 10s
      timeout: 5s
      retries: 12
    command:
      [
        "sh",
        "-lc",
        "if [ \"${ENABLE_LIVE_LOOP:-0}\" = \"1\" ]; then python scripts/live_loop.py --interval 15; else echo 'live_loop disabled (set ENABLE_LIVE_LOOP=1)'; tail -f /dev/null; fi",
      ]
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    # see note above (Coolify/Traefik networking)

  # MCP server (read-only query interface)
  # For Claude Desktop: use stdio transport.
  # For Coolify: expose SSE transport via FASTMCP_HOST/FASTMCP_PORT and MCP_TRANSPORT=sse.
  mcp:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - ./.env
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:postgres@postgres:5432/api_football}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-api_football}
      COLLECTOR_LOG_FILE: /app/logs/collector.jsonl
      MCP_TRANSPORT: ${MCP_TRANSPORT:-sse}
      MCP_MOUNT_PATH: ${MCP_MOUNT_PATH:-}
      FASTMCP_HOST: ${FASTMCP_HOST:-0.0.0.0}
      FASTMCP_PORT: ${FASTMCP_PORT:-8000}
      FASTMCP_LOG_LEVEL: ${FASTMCP_LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
    # Prod (Coolify/Traefik) should route internally to the container port.
    # Avoid publishing host ports to reduce port conflicts and redeploy fragility.
    expose:
      - "${FASTMCP_PORT:-8000}"
    healthcheck:
      test: ["CMD", "python", "scripts/healthcheck_mcp.py"]
      interval: 10s
      timeout: 5s
      retries: 12
    command: ["sh", "-lc", "python -m src.mcp.server"]
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    # see note above (Coolify/Traefik networking)

  # Read API (REST + SSE) for external consumers (read-only, DB-backed)
  read_api:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - ./.env
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:postgres@postgres:5432/api_football}
      POSTGRES_HOST: ${POSTGRES_HOST:-postgres}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-api_football}

      # Access control (recommended in production)
      READ_API_BASIC_USER: ${READ_API_BASIC_USER:-}
      READ_API_BASIC_PASSWORD: ${READ_API_BASIC_PASSWORD:-}
      READ_API_IP_ALLOWLIST: ${READ_API_IP_ALLOWLIST:-}

      # Service port inside container
      READ_API_PORT: ${READ_API_PORT:-8080}
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "${READ_API_HOST_PORT:-8082}:${READ_API_PORT:-8080}"
    healthcheck:
      test: ["CMD", "python", "scripts/healthcheck_read_api.py"]
      interval: 10s
      timeout: 5s
      retries: 12
    command:
      [
        "sh",
        "-lc",
        "uvicorn src.read_api.app:app --host 0.0.0.0 --port ${READ_API_PORT:-8080}",
      ]
    restart: unless-stopped
    # see note above (Coolify/Traefik networking)

volumes:
  postgres_data:

